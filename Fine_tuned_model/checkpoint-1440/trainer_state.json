{
  "best_global_step": 1440,
  "best_metric": 0.8450997837197584,
  "best_model_checkpoint": "./version_2/checkpoint-1440",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 1440,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.034782608695652174,
      "grad_norm": 17.397119522094727,
      "learning_rate": 2.9812500000000003e-05,
      "loss": 12.1357,
      "step": 10
    },
    {
      "epoch": 0.06956521739130435,
      "grad_norm": 21.568485260009766,
      "learning_rate": 2.960416666666667e-05,
      "loss": 5.8953,
      "step": 20
    },
    {
      "epoch": 0.10434782608695652,
      "grad_norm": 10.110234260559082,
      "learning_rate": 2.9395833333333334e-05,
      "loss": 4.3821,
      "step": 30
    },
    {
      "epoch": 0.1391304347826087,
      "grad_norm": 8.643397331237793,
      "learning_rate": 2.91875e-05,
      "loss": 3.9836,
      "step": 40
    },
    {
      "epoch": 0.17391304347826086,
      "grad_norm": 8.413457870483398,
      "learning_rate": 2.897916666666667e-05,
      "loss": 3.8938,
      "step": 50
    },
    {
      "epoch": 0.20869565217391303,
      "grad_norm": 7.910055160522461,
      "learning_rate": 2.8770833333333336e-05,
      "loss": 3.5438,
      "step": 60
    },
    {
      "epoch": 0.24347826086956523,
      "grad_norm": 7.196263790130615,
      "learning_rate": 2.85625e-05,
      "loss": 3.2402,
      "step": 70
    },
    {
      "epoch": 0.2782608695652174,
      "grad_norm": 17.599119186401367,
      "learning_rate": 2.8354166666666667e-05,
      "loss": 3.0041,
      "step": 80
    },
    {
      "epoch": 0.3130434782608696,
      "grad_norm": 5.987663745880127,
      "learning_rate": 2.8145833333333334e-05,
      "loss": 2.7641,
      "step": 90
    },
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 5.071016788482666,
      "learning_rate": 2.79375e-05,
      "loss": 2.5408,
      "step": 100
    },
    {
      "epoch": 0.3826086956521739,
      "grad_norm": 3.6033775806427,
      "learning_rate": 2.772916666666667e-05,
      "loss": 2.4154,
      "step": 110
    },
    {
      "epoch": 0.41739130434782606,
      "grad_norm": 3.223478317260742,
      "learning_rate": 2.7520833333333333e-05,
      "loss": 2.2832,
      "step": 120
    },
    {
      "epoch": 0.45217391304347826,
      "grad_norm": 3.4353253841400146,
      "learning_rate": 2.73125e-05,
      "loss": 2.1924,
      "step": 130
    },
    {
      "epoch": 0.48695652173913045,
      "grad_norm": 3.4525649547576904,
      "learning_rate": 2.7104166666666667e-05,
      "loss": 2.1576,
      "step": 140
    },
    {
      "epoch": 0.5217391304347826,
      "grad_norm": 2.756282329559326,
      "learning_rate": 2.6895833333333334e-05,
      "loss": 2.0928,
      "step": 150
    },
    {
      "epoch": 0.5565217391304348,
      "grad_norm": 3.1239662170410156,
      "learning_rate": 2.6687499999999998e-05,
      "loss": 2.0351,
      "step": 160
    },
    {
      "epoch": 0.591304347826087,
      "grad_norm": 2.3198606967926025,
      "learning_rate": 2.6479166666666665e-05,
      "loss": 2.003,
      "step": 170
    },
    {
      "epoch": 0.6260869565217392,
      "grad_norm": 3.2368111610412598,
      "learning_rate": 2.6270833333333333e-05,
      "loss": 1.9707,
      "step": 180
    },
    {
      "epoch": 0.6608695652173913,
      "grad_norm": 1.3498972654342651,
      "learning_rate": 2.60625e-05,
      "loss": 1.9202,
      "step": 190
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 1.5908135175704956,
      "learning_rate": 2.5854166666666667e-05,
      "loss": 1.8979,
      "step": 200
    },
    {
      "epoch": 0.7304347826086957,
      "grad_norm": 1.1150009632110596,
      "learning_rate": 2.5645833333333334e-05,
      "loss": 1.8666,
      "step": 210
    },
    {
      "epoch": 0.7652173913043478,
      "grad_norm": 1.0443670749664307,
      "learning_rate": 2.54375e-05,
      "loss": 1.8818,
      "step": 220
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7305792570114136,
      "learning_rate": 2.522916666666667e-05,
      "loss": 1.8457,
      "step": 230
    },
    {
      "epoch": 0.8347826086956521,
      "grad_norm": 1.5320870876312256,
      "learning_rate": 2.5020833333333336e-05,
      "loss": 1.8261,
      "step": 240
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 1.1096137762069702,
      "learning_rate": 2.48125e-05,
      "loss": 1.7943,
      "step": 250
    },
    {
      "epoch": 0.9043478260869565,
      "grad_norm": 1.0613895654678345,
      "learning_rate": 2.4604166666666667e-05,
      "loss": 1.7796,
      "step": 260
    },
    {
      "epoch": 0.9391304347826087,
      "grad_norm": 1.108823299407959,
      "learning_rate": 2.4395833333333335e-05,
      "loss": 1.7537,
      "step": 270
    },
    {
      "epoch": 0.9739130434782609,
      "grad_norm": 2.3709723949432373,
      "learning_rate": 2.4187500000000002e-05,
      "loss": 1.7765,
      "step": 280
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.727941928206832,
      "eval_loss": 1.7535288333892822,
      "eval_runtime": 68.6748,
      "eval_samples_per_second": 16.76,
      "eval_steps_per_second": 8.387,
      "step": 288
    },
    {
      "epoch": 1.0069565217391305,
      "grad_norm": 1.0821582078933716,
      "learning_rate": 2.397916666666667e-05,
      "loss": 1.6535,
      "step": 290
    },
    {
      "epoch": 1.0417391304347827,
      "grad_norm": 0.8042017221450806,
      "learning_rate": 2.3770833333333333e-05,
      "loss": 1.7312,
      "step": 300
    },
    {
      "epoch": 1.0765217391304347,
      "grad_norm": 0.8120289444923401,
      "learning_rate": 2.35625e-05,
      "loss": 1.7207,
      "step": 310
    },
    {
      "epoch": 1.111304347826087,
      "grad_norm": 0.8327523469924927,
      "learning_rate": 2.3354166666666667e-05,
      "loss": 1.7046,
      "step": 320
    },
    {
      "epoch": 1.146086956521739,
      "grad_norm": 0.8042587041854858,
      "learning_rate": 2.3145833333333335e-05,
      "loss": 1.692,
      "step": 330
    },
    {
      "epoch": 1.1808695652173913,
      "grad_norm": 0.678799033164978,
      "learning_rate": 2.29375e-05,
      "loss": 1.7019,
      "step": 340
    },
    {
      "epoch": 1.2156521739130435,
      "grad_norm": 0.7618395090103149,
      "learning_rate": 2.2729166666666666e-05,
      "loss": 1.6781,
      "step": 350
    },
    {
      "epoch": 1.2504347826086957,
      "grad_norm": 0.9918834567070007,
      "learning_rate": 2.2520833333333333e-05,
      "loss": 1.6819,
      "step": 360
    },
    {
      "epoch": 1.2852173913043479,
      "grad_norm": 0.7806727290153503,
      "learning_rate": 2.23125e-05,
      "loss": 1.6688,
      "step": 370
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.1093509197235107,
      "learning_rate": 2.2104166666666667e-05,
      "loss": 1.712,
      "step": 380
    },
    {
      "epoch": 1.3547826086956523,
      "grad_norm": 0.5836107730865479,
      "learning_rate": 2.189583333333333e-05,
      "loss": 1.6613,
      "step": 390
    },
    {
      "epoch": 1.3895652173913042,
      "grad_norm": 1.0000085830688477,
      "learning_rate": 2.16875e-05,
      "loss": 1.661,
      "step": 400
    },
    {
      "epoch": 1.4243478260869566,
      "grad_norm": 0.9708404541015625,
      "learning_rate": 2.1479166666666666e-05,
      "loss": 1.6567,
      "step": 410
    },
    {
      "epoch": 1.4591304347826086,
      "grad_norm": 0.9454196691513062,
      "learning_rate": 2.1270833333333336e-05,
      "loss": 1.6619,
      "step": 420
    },
    {
      "epoch": 1.4939130434782608,
      "grad_norm": 0.8098240494728088,
      "learning_rate": 2.10625e-05,
      "loss": 1.6448,
      "step": 430
    },
    {
      "epoch": 1.528695652173913,
      "grad_norm": 0.6504934430122375,
      "learning_rate": 2.0854166666666668e-05,
      "loss": 1.6452,
      "step": 440
    },
    {
      "epoch": 1.5634782608695652,
      "grad_norm": 31.088275909423828,
      "learning_rate": 2.0645833333333335e-05,
      "loss": 1.6448,
      "step": 450
    },
    {
      "epoch": 1.5982608695652174,
      "grad_norm": 1.7890712022781372,
      "learning_rate": 2.0437500000000002e-05,
      "loss": 1.6417,
      "step": 460
    },
    {
      "epoch": 1.6330434782608696,
      "grad_norm": 1.153709053993225,
      "learning_rate": 2.022916666666667e-05,
      "loss": 1.639,
      "step": 470
    },
    {
      "epoch": 1.6678260869565218,
      "grad_norm": 1.0222724676132202,
      "learning_rate": 2.0020833333333333e-05,
      "loss": 1.6343,
      "step": 480
    },
    {
      "epoch": 1.7026086956521738,
      "grad_norm": 0.6733580231666565,
      "learning_rate": 1.98125e-05,
      "loss": 1.6174,
      "step": 490
    },
    {
      "epoch": 1.7373913043478262,
      "grad_norm": 1.8047277927398682,
      "learning_rate": 1.9604166666666668e-05,
      "loss": 1.6259,
      "step": 500
    },
    {
      "epoch": 1.7721739130434782,
      "grad_norm": 0.7083869576454163,
      "learning_rate": 1.9395833333333335e-05,
      "loss": 1.6147,
      "step": 510
    },
    {
      "epoch": 1.8069565217391306,
      "grad_norm": 0.7542096376419067,
      "learning_rate": 1.91875e-05,
      "loss": 1.6095,
      "step": 520
    },
    {
      "epoch": 1.8417391304347825,
      "grad_norm": 0.7592920064926147,
      "learning_rate": 1.8979166666666666e-05,
      "loss": 1.6176,
      "step": 530
    },
    {
      "epoch": 1.8765217391304347,
      "grad_norm": 0.6461852788925171,
      "learning_rate": 1.8770833333333333e-05,
      "loss": 1.6024,
      "step": 540
    },
    {
      "epoch": 1.911304347826087,
      "grad_norm": 0.7780216932296753,
      "learning_rate": 1.85625e-05,
      "loss": 1.594,
      "step": 550
    },
    {
      "epoch": 1.9460869565217391,
      "grad_norm": 0.6985207796096802,
      "learning_rate": 1.8354166666666668e-05,
      "loss": 1.5993,
      "step": 560
    },
    {
      "epoch": 1.9808695652173913,
      "grad_norm": 0.7877228856086731,
      "learning_rate": 1.814583333333333e-05,
      "loss": 1.6058,
      "step": 570
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.7610996837248968,
      "eval_loss": 1.5792911052703857,
      "eval_runtime": 56.6333,
      "eval_samples_per_second": 20.324,
      "eval_steps_per_second": 10.171,
      "step": 576
    },
    {
      "epoch": 2.013913043478261,
      "grad_norm": 0.6602001190185547,
      "learning_rate": 1.79375e-05,
      "loss": 1.5133,
      "step": 580
    },
    {
      "epoch": 2.048695652173913,
      "grad_norm": 0.9951708912849426,
      "learning_rate": 1.7729166666666666e-05,
      "loss": 1.5827,
      "step": 590
    },
    {
      "epoch": 2.0834782608695654,
      "grad_norm": 0.8000741004943848,
      "learning_rate": 1.7520833333333333e-05,
      "loss": 1.5888,
      "step": 600
    },
    {
      "epoch": 2.1182608695652174,
      "grad_norm": 0.7765610814094543,
      "learning_rate": 1.7312499999999997e-05,
      "loss": 1.5731,
      "step": 610
    },
    {
      "epoch": 2.1530434782608694,
      "grad_norm": 1.11387300491333,
      "learning_rate": 1.7104166666666668e-05,
      "loss": 1.5898,
      "step": 620
    },
    {
      "epoch": 2.187826086956522,
      "grad_norm": 1.0417771339416504,
      "learning_rate": 1.6895833333333335e-05,
      "loss": 1.5795,
      "step": 630
    },
    {
      "epoch": 2.222608695652174,
      "grad_norm": 0.777374804019928,
      "learning_rate": 1.6687500000000002e-05,
      "loss": 1.5733,
      "step": 640
    },
    {
      "epoch": 2.257391304347826,
      "grad_norm": 0.7387911677360535,
      "learning_rate": 1.647916666666667e-05,
      "loss": 1.5725,
      "step": 650
    },
    {
      "epoch": 2.292173913043478,
      "grad_norm": 0.9509759545326233,
      "learning_rate": 1.6270833333333334e-05,
      "loss": 1.5802,
      "step": 660
    },
    {
      "epoch": 2.3269565217391306,
      "grad_norm": 10.963128089904785,
      "learning_rate": 1.60625e-05,
      "loss": 1.5919,
      "step": 670
    },
    {
      "epoch": 2.3617391304347826,
      "grad_norm": 0.6235551834106445,
      "learning_rate": 1.5854166666666668e-05,
      "loss": 1.5799,
      "step": 680
    },
    {
      "epoch": 2.396521739130435,
      "grad_norm": 0.8615096211433411,
      "learning_rate": 1.5645833333333335e-05,
      "loss": 1.5664,
      "step": 690
    },
    {
      "epoch": 2.431304347826087,
      "grad_norm": 0.7064409852027893,
      "learning_rate": 1.54375e-05,
      "loss": 1.56,
      "step": 700
    },
    {
      "epoch": 2.466086956521739,
      "grad_norm": 0.726302981376648,
      "learning_rate": 1.5229166666666666e-05,
      "loss": 1.566,
      "step": 710
    },
    {
      "epoch": 2.5008695652173913,
      "grad_norm": 0.7566271424293518,
      "learning_rate": 1.5020833333333334e-05,
      "loss": 1.5607,
      "step": 720
    },
    {
      "epoch": 2.5356521739130433,
      "grad_norm": 0.9783593416213989,
      "learning_rate": 1.4812500000000001e-05,
      "loss": 1.5682,
      "step": 730
    },
    {
      "epoch": 2.5704347826086957,
      "grad_norm": 0.5668090581893921,
      "learning_rate": 1.4604166666666666e-05,
      "loss": 1.5686,
      "step": 740
    },
    {
      "epoch": 2.6052173913043477,
      "grad_norm": 0.8467435836791992,
      "learning_rate": 1.4395833333333334e-05,
      "loss": 1.5583,
      "step": 750
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.7339785695075989,
      "learning_rate": 1.41875e-05,
      "loss": 1.5595,
      "step": 760
    },
    {
      "epoch": 2.674782608695652,
      "grad_norm": 0.5296136140823364,
      "learning_rate": 1.3979166666666667e-05,
      "loss": 1.5654,
      "step": 770
    },
    {
      "epoch": 2.7095652173913045,
      "grad_norm": 0.7155202627182007,
      "learning_rate": 1.3770833333333334e-05,
      "loss": 1.5564,
      "step": 780
    },
    {
      "epoch": 2.7443478260869565,
      "grad_norm": 0.659907341003418,
      "learning_rate": 1.3562500000000001e-05,
      "loss": 1.5521,
      "step": 790
    },
    {
      "epoch": 2.7791304347826085,
      "grad_norm": 0.7248252630233765,
      "learning_rate": 1.3354166666666667e-05,
      "loss": 1.5642,
      "step": 800
    },
    {
      "epoch": 2.813913043478261,
      "grad_norm": 0.8067007064819336,
      "learning_rate": 1.3145833333333334e-05,
      "loss": 1.5535,
      "step": 810
    },
    {
      "epoch": 2.8486956521739133,
      "grad_norm": 0.8801413774490356,
      "learning_rate": 1.2937500000000001e-05,
      "loss": 1.5564,
      "step": 820
    },
    {
      "epoch": 2.8834782608695653,
      "grad_norm": 0.5787802934646606,
      "learning_rate": 1.2729166666666667e-05,
      "loss": 1.5599,
      "step": 830
    },
    {
      "epoch": 2.9182608695652172,
      "grad_norm": 0.6591511964797974,
      "learning_rate": 1.2520833333333334e-05,
      "loss": 1.548,
      "step": 840
    },
    {
      "epoch": 2.9530434782608697,
      "grad_norm": 1.021690011024475,
      "learning_rate": 1.23125e-05,
      "loss": 1.5674,
      "step": 850
    },
    {
      "epoch": 2.9878260869565216,
      "grad_norm": 0.6246547698974609,
      "learning_rate": 1.2104166666666667e-05,
      "loss": 1.55,
      "step": 860
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.822320108199574,
      "eval_loss": 1.5308367013931274,
      "eval_runtime": 56.3767,
      "eval_samples_per_second": 20.416,
      "eval_steps_per_second": 10.217,
      "step": 864
    },
    {
      "epoch": 3.0208695652173914,
      "grad_norm": 0.8995475769042969,
      "learning_rate": 1.1895833333333332e-05,
      "loss": 1.4676,
      "step": 870
    },
    {
      "epoch": 3.0556521739130433,
      "grad_norm": 0.7669232487678528,
      "learning_rate": 1.1687500000000001e-05,
      "loss": 1.5422,
      "step": 880
    },
    {
      "epoch": 3.0904347826086958,
      "grad_norm": 0.9263964891433716,
      "learning_rate": 1.1479166666666667e-05,
      "loss": 1.5548,
      "step": 890
    },
    {
      "epoch": 3.1252173913043477,
      "grad_norm": 0.8410574197769165,
      "learning_rate": 1.1270833333333334e-05,
      "loss": 1.5601,
      "step": 900
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.45179229974746704,
      "learning_rate": 1.1062500000000001e-05,
      "loss": 1.5322,
      "step": 910
    },
    {
      "epoch": 3.194782608695652,
      "grad_norm": 0.778497040271759,
      "learning_rate": 1.0854166666666667e-05,
      "loss": 1.5426,
      "step": 920
    },
    {
      "epoch": 3.2295652173913045,
      "grad_norm": 0.6950082778930664,
      "learning_rate": 1.0645833333333334e-05,
      "loss": 1.5384,
      "step": 930
    },
    {
      "epoch": 3.2643478260869565,
      "grad_norm": 1.3393315076828003,
      "learning_rate": 1.04375e-05,
      "loss": 1.5414,
      "step": 940
    },
    {
      "epoch": 3.299130434782609,
      "grad_norm": 0.5850030779838562,
      "learning_rate": 1.0229166666666667e-05,
      "loss": 1.5407,
      "step": 950
    },
    {
      "epoch": 3.333913043478261,
      "grad_norm": 0.8438093662261963,
      "learning_rate": 1.0020833333333332e-05,
      "loss": 1.5424,
      "step": 960
    },
    {
      "epoch": 3.368695652173913,
      "grad_norm": 0.44373995065689087,
      "learning_rate": 9.8125e-06,
      "loss": 1.5363,
      "step": 970
    },
    {
      "epoch": 3.4034782608695653,
      "grad_norm": 0.8599722385406494,
      "learning_rate": 9.604166666666667e-06,
      "loss": 1.538,
      "step": 980
    },
    {
      "epoch": 3.4382608695652173,
      "grad_norm": 0.64140784740448,
      "learning_rate": 9.395833333333334e-06,
      "loss": 1.5297,
      "step": 990
    },
    {
      "epoch": 3.4730434782608697,
      "grad_norm": 0.9587126970291138,
      "learning_rate": 9.187500000000001e-06,
      "loss": 1.5339,
      "step": 1000
    },
    {
      "epoch": 3.5078260869565216,
      "grad_norm": 0.7974767684936523,
      "learning_rate": 8.979166666666667e-06,
      "loss": 1.5357,
      "step": 1010
    },
    {
      "epoch": 3.542608695652174,
      "grad_norm": 1.0788110494613647,
      "learning_rate": 8.770833333333334e-06,
      "loss": 1.5282,
      "step": 1020
    },
    {
      "epoch": 3.577391304347826,
      "grad_norm": 0.5480468273162842,
      "learning_rate": 8.5625e-06,
      "loss": 1.5278,
      "step": 1030
    },
    {
      "epoch": 3.6121739130434785,
      "grad_norm": 0.6964618563652039,
      "learning_rate": 8.354166666666667e-06,
      "loss": 1.5407,
      "step": 1040
    },
    {
      "epoch": 3.6469565217391304,
      "grad_norm": 0.5677040815353394,
      "learning_rate": 8.145833333333333e-06,
      "loss": 1.5357,
      "step": 1050
    },
    {
      "epoch": 3.6817391304347824,
      "grad_norm": 0.5892817974090576,
      "learning_rate": 7.9375e-06,
      "loss": 1.5425,
      "step": 1060
    },
    {
      "epoch": 3.716521739130435,
      "grad_norm": 0.8604958057403564,
      "learning_rate": 7.729166666666665e-06,
      "loss": 1.5228,
      "step": 1070
    },
    {
      "epoch": 3.751304347826087,
      "grad_norm": 0.43521013855934143,
      "learning_rate": 7.5208333333333335e-06,
      "loss": 1.5278,
      "step": 1080
    },
    {
      "epoch": 3.786086956521739,
      "grad_norm": 0.6073728203773499,
      "learning_rate": 7.3125e-06,
      "loss": 1.5313,
      "step": 1090
    },
    {
      "epoch": 3.820869565217391,
      "grad_norm": 0.5907704830169678,
      "learning_rate": 7.104166666666666e-06,
      "loss": 1.5292,
      "step": 1100
    },
    {
      "epoch": 3.8556521739130436,
      "grad_norm": 0.5622506737709045,
      "learning_rate": 6.8958333333333335e-06,
      "loss": 1.5371,
      "step": 1110
    },
    {
      "epoch": 3.8904347826086956,
      "grad_norm": 0.8066579699516296,
      "learning_rate": 6.687500000000001e-06,
      "loss": 1.5341,
      "step": 1120
    },
    {
      "epoch": 3.925217391304348,
      "grad_norm": 0.6237766742706299,
      "learning_rate": 6.479166666666667e-06,
      "loss": 1.5274,
      "step": 1130
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.5138034224510193,
      "learning_rate": 6.2708333333333336e-06,
      "loss": 1.5317,
      "step": 1140
    },
    {
      "epoch": 3.994782608695652,
      "grad_norm": 0.6818787455558777,
      "learning_rate": 6.0625e-06,
      "loss": 1.534,
      "step": 1150
    },
    {
      "epoch": 4.0,
      "eval_f1": 0.8387741708789822,
      "eval_loss": 1.5123037099838257,
      "eval_runtime": 56.755,
      "eval_samples_per_second": 20.28,
      "eval_steps_per_second": 10.149,
      "step": 1152
    },
    {
      "epoch": 4.027826086956522,
      "grad_norm": 0.5244377851486206,
      "learning_rate": 5.854166666666667e-06,
      "loss": 1.4503,
      "step": 1160
    },
    {
      "epoch": 4.062608695652174,
      "grad_norm": 0.6720464825630188,
      "learning_rate": 5.645833333333334e-06,
      "loss": 1.521,
      "step": 1170
    },
    {
      "epoch": 4.097391304347826,
      "grad_norm": 0.6909297704696655,
      "learning_rate": 5.4375e-06,
      "loss": 1.5258,
      "step": 1180
    },
    {
      "epoch": 4.132173913043478,
      "grad_norm": 0.821200966835022,
      "learning_rate": 5.2291666666666664e-06,
      "loss": 1.5192,
      "step": 1190
    },
    {
      "epoch": 4.166956521739131,
      "grad_norm": 0.6127964854240417,
      "learning_rate": 5.020833333333333e-06,
      "loss": 1.5201,
      "step": 1200
    },
    {
      "epoch": 4.201739130434783,
      "grad_norm": 0.47293558716773987,
      "learning_rate": 4.812500000000001e-06,
      "loss": 1.52,
      "step": 1210
    },
    {
      "epoch": 4.236521739130435,
      "grad_norm": 0.46852320432662964,
      "learning_rate": 4.604166666666667e-06,
      "loss": 1.5166,
      "step": 1220
    },
    {
      "epoch": 4.271304347826087,
      "grad_norm": 0.9372474551200867,
      "learning_rate": 4.395833333333334e-06,
      "loss": 1.5299,
      "step": 1230
    },
    {
      "epoch": 4.306086956521739,
      "grad_norm": 0.7791257500648499,
      "learning_rate": 4.1875e-06,
      "loss": 1.5122,
      "step": 1240
    },
    {
      "epoch": 4.340869565217392,
      "grad_norm": 0.8545266389846802,
      "learning_rate": 3.9791666666666665e-06,
      "loss": 1.5273,
      "step": 1250
    },
    {
      "epoch": 4.375652173913044,
      "grad_norm": 0.7292509078979492,
      "learning_rate": 3.7708333333333334e-06,
      "loss": 1.5242,
      "step": 1260
    },
    {
      "epoch": 4.410434782608696,
      "grad_norm": 0.9283705949783325,
      "learning_rate": 3.5624999999999998e-06,
      "loss": 1.526,
      "step": 1270
    },
    {
      "epoch": 4.445217391304348,
      "grad_norm": 0.8231478333473206,
      "learning_rate": 3.354166666666667e-06,
      "loss": 1.5237,
      "step": 1280
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.5217267274856567,
      "learning_rate": 3.1458333333333334e-06,
      "loss": 1.5246,
      "step": 1290
    },
    {
      "epoch": 4.514782608695652,
      "grad_norm": 0.6688864827156067,
      "learning_rate": 2.9375000000000003e-06,
      "loss": 1.5262,
      "step": 1300
    },
    {
      "epoch": 4.549565217391304,
      "grad_norm": 0.5816426873207092,
      "learning_rate": 2.7291666666666667e-06,
      "loss": 1.5179,
      "step": 1310
    },
    {
      "epoch": 4.584347826086956,
      "grad_norm": 0.5639399290084839,
      "learning_rate": 2.5208333333333335e-06,
      "loss": 1.5291,
      "step": 1320
    },
    {
      "epoch": 4.619130434782608,
      "grad_norm": 0.6128799915313721,
      "learning_rate": 2.3125000000000003e-06,
      "loss": 1.5329,
      "step": 1330
    },
    {
      "epoch": 4.653913043478261,
      "grad_norm": 0.49810895323753357,
      "learning_rate": 2.1041666666666667e-06,
      "loss": 1.5132,
      "step": 1340
    },
    {
      "epoch": 4.688695652173913,
      "grad_norm": 0.6955443620681763,
      "learning_rate": 1.8958333333333333e-06,
      "loss": 1.525,
      "step": 1350
    },
    {
      "epoch": 4.723478260869565,
      "grad_norm": 0.5973645448684692,
      "learning_rate": 1.6875000000000001e-06,
      "loss": 1.5273,
      "step": 1360
    },
    {
      "epoch": 4.758260869565217,
      "grad_norm": 0.4856094419956207,
      "learning_rate": 1.4791666666666666e-06,
      "loss": 1.5171,
      "step": 1370
    },
    {
      "epoch": 4.79304347826087,
      "grad_norm": 0.5645008087158203,
      "learning_rate": 1.2708333333333334e-06,
      "loss": 1.5242,
      "step": 1380
    },
    {
      "epoch": 4.827826086956522,
      "grad_norm": 0.46570026874542236,
      "learning_rate": 1.0625e-06,
      "loss": 1.519,
      "step": 1390
    },
    {
      "epoch": 4.862608695652174,
      "grad_norm": 0.4412252604961395,
      "learning_rate": 8.541666666666667e-07,
      "loss": 1.5252,
      "step": 1400
    },
    {
      "epoch": 4.897391304347826,
      "grad_norm": 0.7373466491699219,
      "learning_rate": 6.458333333333333e-07,
      "loss": 1.5173,
      "step": 1410
    },
    {
      "epoch": 4.932173913043478,
      "grad_norm": 0.6492341160774231,
      "learning_rate": 4.375e-07,
      "loss": 1.514,
      "step": 1420
    },
    {
      "epoch": 4.966956521739131,
      "grad_norm": 0.85060054063797,
      "learning_rate": 2.2916666666666666e-07,
      "loss": 1.5195,
      "step": 1430
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.38842537999153137,
      "learning_rate": 2.0833333333333335e-08,
      "loss": 1.4446,
      "step": 1440
    },
    {
      "epoch": 5.0,
      "eval_f1": 0.8450997837197584,
      "eval_loss": 1.50503671169281,
      "eval_runtime": 56.1869,
      "eval_samples_per_second": 20.485,
      "eval_steps_per_second": 10.252,
      "step": 1440
    }
  ],
  "logging_steps": 10,
  "max_steps": 1440,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6504831434752e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
