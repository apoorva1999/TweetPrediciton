{
  "best_global_step": 288,
  "best_metric": 0.727941928206832,
  "best_model_checkpoint": "./version_2/checkpoint-288",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 288,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.034782608695652174,
      "grad_norm": 17.397119522094727,
      "learning_rate": 2.9812500000000003e-05,
      "loss": 12.1357,
      "step": 10
    },
    {
      "epoch": 0.06956521739130435,
      "grad_norm": 21.568485260009766,
      "learning_rate": 2.960416666666667e-05,
      "loss": 5.8953,
      "step": 20
    },
    {
      "epoch": 0.10434782608695652,
      "grad_norm": 10.110234260559082,
      "learning_rate": 2.9395833333333334e-05,
      "loss": 4.3821,
      "step": 30
    },
    {
      "epoch": 0.1391304347826087,
      "grad_norm": 8.643397331237793,
      "learning_rate": 2.91875e-05,
      "loss": 3.9836,
      "step": 40
    },
    {
      "epoch": 0.17391304347826086,
      "grad_norm": 8.413457870483398,
      "learning_rate": 2.897916666666667e-05,
      "loss": 3.8938,
      "step": 50
    },
    {
      "epoch": 0.20869565217391303,
      "grad_norm": 7.910055160522461,
      "learning_rate": 2.8770833333333336e-05,
      "loss": 3.5438,
      "step": 60
    },
    {
      "epoch": 0.24347826086956523,
      "grad_norm": 7.196263790130615,
      "learning_rate": 2.85625e-05,
      "loss": 3.2402,
      "step": 70
    },
    {
      "epoch": 0.2782608695652174,
      "grad_norm": 17.599119186401367,
      "learning_rate": 2.8354166666666667e-05,
      "loss": 3.0041,
      "step": 80
    },
    {
      "epoch": 0.3130434782608696,
      "grad_norm": 5.987663745880127,
      "learning_rate": 2.8145833333333334e-05,
      "loss": 2.7641,
      "step": 90
    },
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 5.071016788482666,
      "learning_rate": 2.79375e-05,
      "loss": 2.5408,
      "step": 100
    },
    {
      "epoch": 0.3826086956521739,
      "grad_norm": 3.6033775806427,
      "learning_rate": 2.772916666666667e-05,
      "loss": 2.4154,
      "step": 110
    },
    {
      "epoch": 0.41739130434782606,
      "grad_norm": 3.223478317260742,
      "learning_rate": 2.7520833333333333e-05,
      "loss": 2.2832,
      "step": 120
    },
    {
      "epoch": 0.45217391304347826,
      "grad_norm": 3.4353253841400146,
      "learning_rate": 2.73125e-05,
      "loss": 2.1924,
      "step": 130
    },
    {
      "epoch": 0.48695652173913045,
      "grad_norm": 3.4525649547576904,
      "learning_rate": 2.7104166666666667e-05,
      "loss": 2.1576,
      "step": 140
    },
    {
      "epoch": 0.5217391304347826,
      "grad_norm": 2.756282329559326,
      "learning_rate": 2.6895833333333334e-05,
      "loss": 2.0928,
      "step": 150
    },
    {
      "epoch": 0.5565217391304348,
      "grad_norm": 3.1239662170410156,
      "learning_rate": 2.6687499999999998e-05,
      "loss": 2.0351,
      "step": 160
    },
    {
      "epoch": 0.591304347826087,
      "grad_norm": 2.3198606967926025,
      "learning_rate": 2.6479166666666665e-05,
      "loss": 2.003,
      "step": 170
    },
    {
      "epoch": 0.6260869565217392,
      "grad_norm": 3.2368111610412598,
      "learning_rate": 2.6270833333333333e-05,
      "loss": 1.9707,
      "step": 180
    },
    {
      "epoch": 0.6608695652173913,
      "grad_norm": 1.3498972654342651,
      "learning_rate": 2.60625e-05,
      "loss": 1.9202,
      "step": 190
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 1.5908135175704956,
      "learning_rate": 2.5854166666666667e-05,
      "loss": 1.8979,
      "step": 200
    },
    {
      "epoch": 0.7304347826086957,
      "grad_norm": 1.1150009632110596,
      "learning_rate": 2.5645833333333334e-05,
      "loss": 1.8666,
      "step": 210
    },
    {
      "epoch": 0.7652173913043478,
      "grad_norm": 1.0443670749664307,
      "learning_rate": 2.54375e-05,
      "loss": 1.8818,
      "step": 220
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7305792570114136,
      "learning_rate": 2.522916666666667e-05,
      "loss": 1.8457,
      "step": 230
    },
    {
      "epoch": 0.8347826086956521,
      "grad_norm": 1.5320870876312256,
      "learning_rate": 2.5020833333333336e-05,
      "loss": 1.8261,
      "step": 240
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 1.1096137762069702,
      "learning_rate": 2.48125e-05,
      "loss": 1.7943,
      "step": 250
    },
    {
      "epoch": 0.9043478260869565,
      "grad_norm": 1.0613895654678345,
      "learning_rate": 2.4604166666666667e-05,
      "loss": 1.7796,
      "step": 260
    },
    {
      "epoch": 0.9391304347826087,
      "grad_norm": 1.108823299407959,
      "learning_rate": 2.4395833333333335e-05,
      "loss": 1.7537,
      "step": 270
    },
    {
      "epoch": 0.9739130434782609,
      "grad_norm": 2.3709723949432373,
      "learning_rate": 2.4187500000000002e-05,
      "loss": 1.7765,
      "step": 280
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.727941928206832,
      "eval_loss": 1.7535288333892822,
      "eval_runtime": 68.6748,
      "eval_samples_per_second": 16.76,
      "eval_steps_per_second": 8.387,
      "step": 288
    }
  ],
  "logging_steps": 10,
  "max_steps": 1440,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5300966286950400.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
